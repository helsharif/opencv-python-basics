{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be5e4bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Husayn El Sharif\n",
    "comment = \"\"\"\n",
    "Learning the basics of OpenCV and image processing with Python.\n",
    "See: https://www.youtube.com/watch?v=x7n85SJMjUA\n",
    "\n",
    "Note: OpenCV uses BGR color format by default, unlike most other libraries that use RGB.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec9f12c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "87749b9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read example image\n",
    "img_path = \"example_images/GSFC_20240729_OSAM1_064345~medium.jpg\"\n",
    "\n",
    "# read image\n",
    "image = cv2.imread(img_path)\n",
    "\n",
    "# show image\n",
    "cv2.imshow('NASA Image', image)\n",
    "cv2.waitKey(0) # Wait for a key press to close the window, 0 means wait indefinitely. If I put a number, thne it will wait that many milliseconds before closing the window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d5f7e55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert image to grayscale\n",
    "gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "cv2.imshow('Gray NASA Image', gray_image)\n",
    "cv2.waitKey(0) # Wait for a key press to close the window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "559d53e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save gray image\n",
    "cv2.imwrite('example_images/GSFC_20240729_OSAM1_064345_gray.jpg', gray_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c699f08e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gray Image Size: Width=1280, Height=853\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get image size of gray image\n",
    "height, width = gray_image.shape\n",
    "print(f'Gray Image Size: Width={width}, Height={height}')\n",
    "cropped_image = gray_image[100:400, 100:1000] \n",
    " \n",
    "# put text on the cropped image\n",
    "cv2.putText(cropped_image, 'Cropped Image', (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 0), 2, cv2.LINE_AA) # white text, thickness 2, anti-aliased. 1 is font scale\n",
    "\n",
    "cv2.imshow('Cropped Gray NASA Image', cropped_image)\n",
    "cv2.waitKey(10) # Wait for a key press to close the window\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f8cc0844",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rotate image 45 degrees clockwise \n",
    "(h, w) = gray_image.shape\n",
    "center = (w // 2, h // 2)\n",
    "M = cv2.getRotationMatrix2D(center, -45, 1.0) # negative angle for clockwise rotation, 1.0 is the scale factor\n",
    "rotated_image = cv2.warpAffine(gray_image, M, (w, h))\n",
    "cv2.imshow('Rotated Gray NASA Image', rotated_image)\n",
    "cv2.waitKey(5) # Wait for a key press to close the window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7c121918",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Image Thresholding\n",
    "_, thresholded_image = cv2.threshold(gray_image, 127, 255, cv2.THRESH_BINARY) # from the pixels with value greater than 120, set to 255 (white), else set to 0 (black). This creates a binary image\n",
    "cv2.imshow('Thresholded Gray NASA Image', thresholded_image)\n",
    "cv2.waitKey(10) # Wait for a key press to close the window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9db9cebc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adaptive Thresholding\n",
    "adaptive_thresh_image = cv2.adaptiveThreshold(gray_image, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 2) # dark regions become black, light regions become white\n",
    "cv2.imshow('Adaptive Thresholded Gray NASA Image', adaptive_thresh_image)\n",
    "cv2.waitKey(10) # Wait for a key press to close the window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8c53621f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Image Blurring\n",
    "blurred_image = cv2.GaussianBlur(gray_image, (15, 15), 0) # 7x7 kernel, 0 means sigma is calculated based on kernel\n",
    "cv2.imshow('Blurred Gray NASA Image', blurred_image)\n",
    "cv2.waitKey(10) # Wait for a key press to close the window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d92850",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Edge Detection (Sobel), reads horizontal and vertical edges\n",
    "sobel_x = cv2.Sobel(image, cv2.CV_64F, 1, 0, ksize=3) # detect edges in x direction (horizontal)\n",
    "sobel_y = cv2.Sobel(image, cv2.CV_64F, 0, 1, ksize=3) # detect edges in y direction (vertical)\n",
    "sobel_combined = cv2.magnitude(sobel_x, sobel_y)\n",
    "cv2.imshow('Sobel Edge Detection', sobel_combined)\n",
    "cv2.waitKey(10) # Wait for a key press to close the window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3d8518d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Edge Detection using Canny (can detect strong and weak edges and curves)\n",
    "canny_edges = cv2.Canny(image, 100, 200) # low threshold and high threshold\n",
    "cv2.imshow('Canny Edge Detection', canny_edges)\n",
    "cv2.waitKey(10) # Wait for a key press to close the window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "084e4622",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Face Detection\n",
    "# Load the pre-trained Haar Cascade classifier for face detection\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml') # pre-trained model for frontal face detection. OpenCV comes with several pre-trained classifiers for different objects\n",
    "face_img_path = \"example_images/gettyimages-1354028847-612x612.jpg\"\n",
    "face_img_color = cv2.imread(face_img_path)\n",
    "face_img_gray = cv2.cvtColor(face_img_color, cv2.COLOR_BGR2GRAY) # convert to grayscale, as face detection works better on grayscale images\n",
    "\n",
    "# detect faces in the image\n",
    "faces = face_cascade.detectMultiScale(face_img_gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30)) # returns a list of rectangles (x, y, w, h). scaleFactor compensates for faces of different sizes, minNeighbors is how many neighbors each candidate rectangle should have to retain it, minSize is the minimum possible object size\n",
    "\n",
    "# draw rectangles around detected faces\n",
    "for (x, y, w, h) in faces:\n",
    "    cv2.rectangle(face_img_color, (x, y), (x + w, y + h), (0, 255, 0), 2) # green rectangle with thickness 2\n",
    "\n",
    "# display the output image with detected faces\n",
    "cv2.imshow('Detected Faces', face_img_color)\n",
    "cv2.waitKey(5) # Wait for a key press to close the window\n",
    "\n",
    "# write to example_images/detected_faces.jpg\n",
    "cv2.imwrite('example_images/detected_faces.jpg', face_img_color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b3c05940",
   "metadata": {},
   "outputs": [],
   "source": [
    "# close all windows\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a8f9e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handling Multiple Images"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "opencv_env001",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
